import joblib
import pandas as pd
from pathlib import Path
import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.base import BaseEstimator
from scipy.sparse import csr_matrix
from typing import Any

from src.data.load import load_data
from src.utils.logger import (print_debug, print_info, print_error, print_warning, print_cross_validation_results, \
                              set_global_debug_mode)


class BibleStylePipeline:

    def __init__(self, config: dict[str, Any], debug: bool = False):
        self.config = config
        self.debug = debug
        self.results = {}
        self.vectorizer = None
        self.model = None
        self.best_params = None

        set_global_debug_mode(debug)

    def load_data(self) -> tuple[list, list]:
        dataset_map = {
            'arcaico_moderno': 'train_arcaico_moderno.csv',
            'complexo_simples': 'train_complexo_simples.csv',
            'literal_dinamico': 'train_literal_dinamico.csv'
        }

        dataset_file = dataset_map[self.config["dataset"]]
        print_info(f"Carregando dados do arquivo: {dataset_file}")

        df = load_data(dataset_file)
        print_info(f"Dataframe: {df.shape[0]} linhas, {df.shape[1]} colunas ")

        text_column = "text"
        label_column = "style"

        if self.debug:
            print_debug(f"   üîç Colunas do DataFrame: {df.columns.tolist()}")

        texts = df[text_column].astype(str).tolist()

        labels = df[label_column].values

        print_info(f"Extra√≠dos: {len(texts)} textos e {len(labels)} labels")
        print_info(f"Classes √∫nicas: {np.unique(labels)}")

        return texts, labels

    def extract_features(self, texts: list) -> csr_matrix:
        method = self.config["features"]["method"]
        params = self.config["features"]["params"]

        print_info(f"extraindo features com met√≥do: {method}")

        if method == "bag_of_words":
            from src.features.bag_of_words import create_bag_of_words_vect
            x_vectorized, self.vectorizer = create_bag_of_words_vect(texts, **params)

        elif method == "tfidf":
            raise NotImplementedError

        else:
            raise ValueError(f"M√©todo de features n√£o encontrado: {method}")

        if self.debug:
            print_debug(f"parametros usados{params}")

        return x_vectorized

    def get_model_instance(self, params: dict = None) -> BaseEstimator:
        model_name = self.config["model"]["name"]
        model_params = params or self.config["model"]["params"]

        if self.debug:
            print_debug(f"   ü§ñ Criando modelo {model_name} com par√¢metros: {model_params}")

        if model_name == "logistic_regression":
            from sklearn.linear_model import LogisticRegression
            return LogisticRegression(**model_params)

        elif model_name == "mlp":
            from sklearn.neural_network import MLPClassifier
            return MLPClassifier(**model_params)

        else:
            raise ValueError(f"Modelo n√£o suportado: {model_name}")

    def run_grid_search(self, x, y) -> tuple[BaseEstimator, dict]:
        if "grid_search" not in self.config or not self.config["grid_search"]["enable"]:
            print_info("Grid search desabilitado")
            return self.get_model_instance(), {}

        print_info("Executando grid search")

        grid_config = self.config["grid_search"]
        model = self.get_model_instance()

        if self.debug:
            print_debug(f"parametros do grid: {grid_config['param_grid']}")
            print_debug(f"   scoring: {grid_config['scoring']}")
            print_debug(f"   num_folds: {grid_config['num_folds']}")

        grid_search = GridSearchCV(
            estimator=model,
            param_grid=grid_config["param_grid"],
            scoring=grid_config["scoring"],
            cv=grid_config["num_folds"],
            n_jobs=grid_config.get("n_jobs", 1),
            verbose=grid_config.get("verbose", 1)
        )
        grid_search.fit(x, y)

        print_info("Grid Search conclu√≠do!")
        print_info(f"Melhores par√¢metros: {grid_search.best_params_}")
        print_info(f"Melhor score: {grid_search.best_score_:.4f}")

        return grid_search.best_estimator_, grid_search.best_params_

    def evaluate(self, x, y) -> dict[str, Any]:
        from src.evaluation.cross_validation import evaluate_cross_validation

        print_info("Executando valida√ß√£o cruzada...")

        eval_params = self.config['model']['params'].copy()
        if 'n_jobs' in eval_params:
            eval_params['n_jobs'] = 1

        model = self.get_model_instance(eval_params)

        results = evaluate_cross_validation(
            model,
            x,
            y,
            num_folds=self.config['evaluation']['folds'],
            random_state=self.config['evaluation']['random_state']
        )

        return results

    def train_final_model(self, x, y):
        print_info("Treinando modelo final...")

        if self.config['grid_search']['enable']:
            self.model, self.best_params = self.run_grid_search(x, y)
        else:
            self.model = self.get_model_instance()
            self.model.fit(x, y)

            # Avalia√ß√£o r√°pida
        train_accuracy = self.model.score(x, y)
        print_info(f"Acur√°cia no treino completo: {train_accuracy:.3f}")

        return self.model

    def save_model(self):
        if self.model is None:
            print_warning("Nada para salvar - modelo n√£o dispon√≠vel")
            return

        model_dir = Path("models/saved")
        model_dir.mkdir(exist_ok=True, parents=True)

        base_name = f"{self.config['dataset']}_{self.config['features']['method']}_{self.config['model']['name']}"

        model_path = model_dir / f"{base_name}_model.pkl"
        joblib.dump(self.model, model_path)

        if self.vectorizer is not None:
            vectorizer_path = model_dir / f"{base_name}_vectorizer.pkl"
            joblib.dump(self.vectorizer, vectorizer_path)
            if self.debug:
                print_debug(f"Vectorizer salvo: {vectorizer_path}")

        if self.best_params:
            results_path = model_dir / f'{base_name}_grid_search_results.joblib'
            joblib.dump({
                'best_params': self.best_params,
                'best_score': self.model.score if hasattr(self.model, 'score') else None,
                'config': self.config
            }, results_path)
            if self.debug:
                print_debug(f"   üìä Resultados Grid Search salvos: {results_path}")

        print_info(f"Modelo completo salvo em: {model_dir}/")

        return model_path

    def run(self):
        print_info(f"Pipeline: {self.config['dataset']} | "
                   f"{self.config['features']['method']} | "
                   f"{self.config['model']['name']}"
                   )

        if self.debug:
            print_debug(f"Configura√ß√£o completa: {self.config}")

        try:
            texts, labels = self.load_data()
            x = self.extract_features(texts)

            results = self.evaluate(x, labels)
            self.results = results

            print_cross_validation_results(results, f"{self.config['model']['name']} - {self.config['dataset']}")

            if results['mean_accuracy'] >= self.config['evaluation']['accuracy_threshold']:
                self.train_final_model(x, labels)

                if self.config['evaluation']['save_model']:
                    self.save_model()
            else:
                print_warning(f"Modelo final n√£o treinado - acur√°cia abaixo do threshold")

            return self.results

        except Exception as e:
            print_error(f"Erro no pipeline {e}")
            if self.debug:
                import traceback
                print_debug(f"Stack trace: {traceback.format_exc()}")
            raise


def main():
    config = {
        'dataset': 'arcaico_moderno',
        'features': {
            'method': 'bag_of_words',
            'params': {'ngram': (1, 2)}
        },
        'model': {
            'name': 'logistic_regression',
            'params': {'max_iter': 1200, 'class_weight': 'balanced', 'random_state': 42}
        },
        'evaluation': {
            'folds': 10,
            'random_state': 42,
            'accuracy_threshold': 0.6,
            'save_model': False
        },
        'grid_search': {
            'enable': False
        }
    }

    debug_mode = True
    set_global_debug_mode(debug_mode)
    pipeline = BibleStylePipeline(config, debug=debug_mode)
    results = pipeline.run()

    print_info(f"üéâ Pipeline conclu√≠do! Acur√°cia: {results['mean_accuracy']:.3f}")


if __name__ == "__main__":
    main()


def template_config():
    """
    DOCUMENTA√á√ÉO DE TODAS AS CONFIGURA√á√ïES DE PAR√ÇMETROS DO CONFIG
    """
    return {
        # --- CONFIGURA√á√ïES PRINCIPAIS ---
        'dataset': 'arcaico_moderno',  # Possibilidades: 'arcaico_moderno', 'complexo_simples', 'literal_dinamico'

        # --- CONFIGURA√á√ïES DE FEATURES ---
        'features': {
            'method': 'bag_of_words',  # Possibilidades: 'bag_of_words', 'tfidf'
            'params': {
                # Par√¢metros comuns para ambos os m√©todos:
                'ngrams': (1, 1),  # Possibilidades: (1,1), (1,2), (1,3), (2,2), (2,3)
                'max_features': None,  # Possibilidades: None, 1000, 5000, 10000 (n√∫mero m√°ximo de features)
                'min_df': 1,  # Possibilidades: 1, 2, 5 (m√≠nimo de documentos para feature)
                'max_df': 1.0,  # Possibilidades: 0.7, 0.8, 0.9, 1.0 (m√°ximo de documentos para feature)

                # Par√¢metros espec√≠ficos para TF-IDF:
                'use_idf': True,  # Possibilidades: True, False (usar IDF)
                'smooth_idf': True,  # Possibilidades: True, False (suavizar IDF)
                'sublinear_tf': False,  # Possibilidades: True, False (TF sublinear)
            }
        },

        # --- CONFIGURA√á√ïES DO MODELO ---
        'model': {
            'name': 'logistic_regression',
            # Possibilidades: 'logistic_regression', 'mlp', 'random_forest', 'svm' TODO verificar modelos ap√≥s implementacao
            'params': {
                # --- PAR√ÇMETROS GERAIS ---
                'random_state': 42,  # Para reprodutibilidade

                # --- LOGISTIC REGRESSION ---
                'penalty': 'l2',  # Possibilidades: 'l1', 'l2', 'elasticnet', 'none'
                'C': 1.0,  # Possibilidades: 0.001, 0.01, 0.1, 1.0, 10.0, 100.0
                'solver': 'lbfgs',  # Possibilidades: 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'
                'max_iter': 1000,  # Possibilidades: 100, 500, 1000, 2000
                'class_weight': None,  # Possibilidades: None, 'balanced'
                'n_jobs': -1,  # Possibilidades: -1 (todos cores), 1, 2, 4

                # --- MLP (Multi-Layer Perceptron) ---
                'hidden_layer_sizes': (100,),  # Possibilidades: (50,), (100,), (50, 30), (100, 50), (100, 50, 25)
                'activation': 'relu',  # Possibilidades: 'identity', 'logistic', 'tanh', 'relu'
                'alpha': 0.0001,  # Possibilidades: 0.0001, 0.001, 0.01, 0.1
                'learning_rate': 'constant',  # Possibilidades: 'constant', 'invscaling', 'adaptive'
                'learning_rate_init': 0.001,  # Possibilidades: 0.001, 0.01, 0.1

            }
        },

        # --- CONFIGURA√á√ïES DE AVALIA√á√ÉO ---
        'evaluation': {
            'folds': 5,  # Possibilidades: 3, 5, 10 (n√∫mero de folds na valida√ß√£o cruzada)
            'random_state': 42,  # Seed para reprodutibilidade
            'accuracy_threshold': 0.6,  # Possibilidades: 0.5, 0.6, 0.7, 0.8 (m√≠nimo para salvar modelo)
            'save_model': True,  # Possibilidades: True, False
        },

        # --- CONFIGURA√á√ïES DE GRID SEARCH ---
        'grid_search': {
            'enable': False,  # Possibilidades: True, False
            'scoring': 'accuracy',  # Possibilidades: 'accuracy', 'f1', 'precision', 'recall', 'roc_auc'
            'num_folds': 3,  # Possibilidades: 3, 5 (folds no Grid Search)
            'n_jobs': -1,  # Possibilidades: -1, 1, 2, 4 (paraleliza√ß√£o)
            'verbose': 1,  # Possibilidades: 0, 1, 2, 3 (n√≠vel de log)
            'refit': True,  # Possibilidades: True, False (re-treinar com melhores par√¢metros)

            # Grade de par√¢metros para busca (depende do modelo)
            'param_grid': {
                # Exemplo para Logistic Regression:
                'C': [0.1, 1, 10],
                'solver': ['liblinear', 'saga'],
                'class_weight': [None, 'balanced']

            }
        }
    }
